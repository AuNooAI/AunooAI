model_list:
  - model_name: gpt-4.1-mini
    litellm_params:
      model: openai/gpt-4.1-mini
      api_key: "os.environ/OPENAI_API_KEY_GPT_4.1_MINI"

  - model_name: gpt-4o
    litellm_params:
      model: openai/gpt-4o
      api_key: "os.environ/OPENAI_API_KEY_GPT_4O"

  - model_name: gpt-4o-mini
    litellm_params:
      model: openai/gpt-4o-mini
      api_key: "os.environ/OPENAI_API_KEY_GPT_4O_MINI"

  - model_name: gpt-4.1
    litellm_params:
      model: openai/gpt-4.1
      api_key: "os.environ/OPENAI_API_KEY_GPT_4.1"

  - model_name: gpt-4.1-nano
    litellm_params:
      model: openai/gpt-4.1-nano
      api_key: "os.environ/OPENAI_API_KEY_GPT_4.1_NANO"

  # Hugging Face
  - model_name: mixtral-8x7b
    litellm_params:
      model: huggingface/mistralai/Mixtral-8x7B-Instruct-v0.1
      api_base: "https://api-inference.huggingface.co/models/mistralai/Mixtral-8x7B-Instruct-v0.1"
      api_key: "os.environ/HUGGINGFACE_API_KEY_MIXTRAL_8X7B"
      custom_llm_provider: "huggingface"
  - model_name: claude-4-sonnet-latest

  # Anthropic
    litellm_params:
      model: anthropic/claude-4-sonnet-latest
      api_key: "os.environ/ANTHROPIC_API_KEY_CLAUDE_4_SONNET_LATEST"

  - model_name: claude-3-7-sonnet-latest
    litellm_params:
      model: anthropic/claude-3-7-sonnet-latest
      api_key: "os.environ/ANTHROPIC_API_KEY_CLAUDE_3_7_SONNET_LATEST"

  - model_name: claude-3-5-sonnet-latest
    litellm_params:
      model: anthropic/claude-3-5-sonnet-latest
      api_key: "os.environ/ANTHROPIC_API_KEY_CLAUDE_3_5_SONNET_LATEST"

  - model_name: claude-4-sonnet-latest
    litellm_params:
      model: anthropic/claude-4-sonnet-latest
      api_key: "os.environ/ANTHROPIC_API_KEY_CLAUDE_3_5_SONNET_LATEST"

  # Google
  - model_name: gemini-pro
    litellm_params:
      model: google/gemini-pro
      api_key: "os.environ/GEMINI_API_KEY_GEMINI_PRO"

  # AUNOO models
  # litellm
  - model_name: mixtral
    litellm_params:
      model: openai/mixtral
      api_base: "http://localhost:4000"
      api_key: "os.environ/AUNOOAI_API_KEY_MIXTRAL"
      custom_llm_provider: "openai"

  - model_name: mixtral-instruct
    litellm_params:
      model: openai/mixtral-instruct
      api_base: "http://localhost:4000"
      api_key: "os.environ/AUNOOAI_API_KEY_MIXTRAL_INSTRUCT"
      custom_llm_provider: "openai"

routing_strategy: least-busy
