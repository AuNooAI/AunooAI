model_list:
  # AUNOO models
  - model_name: mixtral
    litellm_params:
      model: aunooai/mixtral
      api_base: "http://localhost:4000"
      api_key: "os.environ/AUNOOAI_API_KEY_MIXTRAL"
      custom_llm_provider: "openai"

  - model_name: mixtral-instruct
    litellm_params:
      model: aunooai/mixtral-instruct
      api_base: "http://localhost:4000"
      api_key: "os.environ/AUNOOAI_API_KEY_MIXTRAL_INSTRUCT"
      custom_llm_provider: "openai"

  - model_name: qwen3-14b
    litellm_params:
      model: qwen2.5-coder:32b
      api_base: "http://localhost:11434"
      custom_llm_provider: "ollama"

  - model_name: qwen3:14b
    litellm_params:
      model: qwen2.5-coder:32b
      api_base: "http://localhost:11434"
      custom_llm_provider: "ollama"

  - model_name: gemma3-27b
    litellm_params:
      model: gemma3:27b
      api_base: "http://localhost:11434"
      custom_llm_provider: "ollama"
      
  - model_name: gemma3:27b
    litellm_params:
      model: gemma3:27b
      api_base: "http://localhost:11434"
      custom_llm_provider: "ollama"

  #  - model_name: nomic-embed-text
  #    litellm_params:
  #      model: aunooai/nomic-embed-text
  #      api_base: "http://5.9.100.178:4000"
  #      api_key: "os.environ/AUNOOAI_API_KEY_NOMIC_EMBED_TEXT"
  #      custom_llm_provider: "openai"

  # OpenAI & other models
  - model_name: gpt-3.5-turbo
    litellm_params:
      model: openai/gpt-3.5-turbo
      api_key: "os.environ/OPENAI_API_KEY_GPT_3.5_TURBO"

#  - model_name: mistral-7b-instruct
#    litellm_params:
#      model: ollama/mistral
#      api_base: "http://localhost:11434" # TODO: change to the correct api base 

  - model_name: mixtral-8x7b
    litellm_params:
      model: huggingface/mistralai/Mixtral-8x7B-Instruct-v0.1
      api_base: "https://api-inference.huggingface.co/models/mistralai/Mixtral-8x7B-Instruct-v0.1"
      api_key: "os.environ/HUGGINGFACE_API_KEY_MIXTRAL_8X7B"
      custom_llm_provider: "huggingface"

  - model_name: gpt-4o
    litellm_params:
      model: openai/gpt-4o
      api_key: "os.environ/OPENAI_API_KEY_GPT_4O"

  - model_name: gpt-4o-mini
    litellm_params:
      model: openai/gpt-4o-mini
      api_key: "os.environ/OPENAI_API_KEY_GPT_4O_MINI"

  - model_name: gpt-4.1
    litellm_params:
      model: openai/gpt-4.1
      api_key: "os.environ/OPENAI_API_KEY_GPT_4.1"

  - model_name: gpt-4.1-mini
    litellm_params:
      model: openai/gpt-4.1-mini
      api_key: "os.environ/OPENAI_API_KEY_GPT_4.1_MINI"

  - model_name: gpt-4.1-nano
    litellm_params:
      model: openai/gpt-4.1-nano
      api_key: "os.environ/OPENAI_API_KEY_GPT_4.1_NANO"

  - model_name: claude-3-7-sonnet-latest
    litellm_params:
      model: anthropic/claude-3-7-sonnet-latest
      api_key: "os.environ/ANTHROPIC_API_KEY_CLAUDE_3_7_SONNET_LATEST"

  - model_name: claude-3-5-sonnet-latest
    litellm_params:
      model: anthropic/claude-3-5-sonnet-latest
      api_key: "os.environ/ANTHROPIC_API_KEY_CLAUDE_3_5_SONNET_LATEST"

  - model_name: gemini-pro
    litellm_params:
      model: google/gemini-pro
      api_key: "os.environ/GEMINI_API_KEY_GEMINI_PRO"

  # Additional Ollama models
  - model_name: phi4-reasoning
    litellm_params:
      model: phi4-reasoning:14b
      api_base: "http://localhost:11434"
      custom_llm_provider: "ollama"

  - model_name: llama3.1
    litellm_params:
      model: llama3.1:8b
      api_base: "http://localhost:11434"
      custom_llm_provider: "ollama"

  - model_name: mistral-small3.1
    litellm_params:
      model: mistral-small3.1:24b
      api_base: "http://localhost:11434"
      custom_llm_provider: "ollama"

fallbacks:
  - gpt-3.5-turbo:
      - gpt-4o
      - claude-3-5-sonnet-latest
  - mistral-7b-instruct:
      - gpt-3.5-turbo
      - claude-3-5-sonnet-latest
  - gpt-4o:
      - claude-3-5-sonnet-latest
      - gpt-3.5-turbo
  - claude-3-5-sonnet-latest:
      - gpt-4o
      - gpt-3.5-turbo
  - qwen3-14b:
      - gpt-4o-mini
      - claude-3-5-sonnet-latest
  - gemma3-27b:
      - gpt-4o-mini
      - claude-3-5-sonnet-latest
  - qwen3:14b:
      - gpt-4o-mini
      - claude-3-5-sonnet-latest
  - gemma3:27b:
      - gpt-4o-mini
      - claude-3-5-sonnet-latest
  - phi4-reasoning:
      - gemma3:27b
      - mistral-small3.1
  - llama3.1:
      - mistral-small3.1
      - phi4-reasoning
  - mistral-small3.1:
      - phi4-reasoning
      - gemma3:27b

routing_strategy: least-busy

models:
  gpt-4:
    model: gpt-4
    max_tokens: 2000
    temperature: 0.7
    
  gpt-3.5-turbo:
    model: gpt-3.5-turbo
    max_tokens: 2000
    temperature: 0.7
    
  claude-2:
    model: claude-2
    max_tokens: 2000
    temperature: 0.7