model_list:
  - model_name: gpt-3.5-turbo
    litellm_params:
      model: openai/gpt-3.5-turbo
      api_key: "os.environ/OPENAI_API_KEY_GPT_3.5_TURBO"

#  - model_name: mistral-7b-instruct
#    litellm_params:
#      model: ollama/mistral
#      api_base: "http://localhost:11434" # TODO: change to the correct api base 

  - model_name: mixtral-8x7b
    litellm_params:
      model: huggingface/mistralai/Mixtral-8x7B-Instruct-v0.1
      api_base: "https://api-inference.huggingface.co/models/mistralai/Mixtral-8x7B-Instruct-v0.1"
      api_key: "os.environ/HUGGINGFACE_API_KEY_MIXTRAL_8X7B"
      custom_llm_provider: "huggingface"

  - model_name: gpt-4o
    litellm_params:
      model: openai/gpt-4o
      api_key: "os.environ/OPENAI_API_KEY_GPT_4O"

  - model_name: gpt-4o-mini
    litellm_params:
      model: openai/gpt-4o-mini
      api_key: "os.environ/OPENAI_API_KEY_GPT_4O_MINI"

  - model_name: claude-3-7-sonnet-latest
    litellm_params:
      model: anthropic/claude-3-7-sonnet-latest
      api_key: "os.environ/ANTHROPIC_API_KEY_CLAUDE_3_7_SONNET_LATEST"

  - model_name: claude-3-5-sonnet-latest
    litellm_params:
      model: anthropic/claude-3-5-sonnet-latest
      api_key: "os.environ/ANTHROPIC_API_KEY_CLAUDE_3_5_SONNET_LATEST"

  - model_name: gemini-pro
    litellm_params:
      model: google/gemini-pro
      api_key: "os.environ/GEMINI_API_KEY_GEMINI_PRO"

fallbacks: [
  {
    "gpt-3.5-turbo": ["gpt-4o", "claude-3-5-sonnet-latest"]
  },
  {
    "mistral-7b-instruct": ["gpt-3.5-turbo", "claude-3-5-sonnet-latest"]
  },
  {
    "gpt-4o": ["claude-3-5-sonnet-latest", "gpt-3.5-turbo"]
  },
  {
    "claude-3-5-sonnet-latest": ["gpt-4o", "gpt-3.5-turbo"]
  }
]

routing_strategy: least-busy