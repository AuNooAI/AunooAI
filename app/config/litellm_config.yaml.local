model_list:
  # AUNOO models 
  #
  # The IP can be changed to localhost when deployed on the server!
  #
  - model_name: mixtral
    litellm_params:
      model: aunooai/mixtral
      api_base: "http://5.9.100.178:4000"
      api_key: "os.environ/AUNOOAI_API_KEY_MIXTRAL"
      custom_llm_provider: "openai"

  - model_name: mixtral-instruct
    litellm_params:
      model: aunooai/mixtral-instruct
      api_base: "http://5.9.100.178:4000"
      api_key: "os.environ/AUNOOAI_API_KEY_MIXTRAL_INSTRUCT"
      custom_llm_provider: "openai"

  - model_name: qwen3:14b
    litellm_params:
      model: aunooai/qwen3
      api_base: "http://5.9.100.178:4000"
      api_key: "os.environ/AUNOOAI_API_KEY_QWEN3"
      custom_llm_provider: "openai"

  - model_name: gemma3:27b
    litellm_params:
      model: aunooai/gemma3
      api_base: "http://5.9.100.178:4000"
      api_key: "os.environ/AUNOOAI_API_KEY_GEMMA3"
      custom_llm_provider: "openai"

  # Additional Ollama models
  - model_name: phi4-reasoning
    litellm_params:
      model: ollama/phi4-reasoning:14b
      api_base: "http://5.9.100.178:11434"
      custom_llm_provider: "ollama"

  - model_name: llama3.1
    litellm_params:
      model: ollama/llama3.1:8b
      api_base: "http://5.9.100.178:11434"
      custom_llm_provider: "ollama"

  - model_name: mistral-small3.1
    litellm_params:
      model: ollama/mistral-small3.1:24b
      api_base: "http://5.9.100.178:11434"
      custom_llm_provider: "ollama"
